{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tanish's\\AppData\\Local\\Temp\\ipykernel_19224\\2848629800.py:22: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n",
      "  box = np.int0(box)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (229,429,3) into shape (1,0,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 41\u001b[0m\n\u001b[0;32m     38\u001b[0m     rotated \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mwarpAffine(img, rotationMatrix, (width, height), flags\u001b[39m=\u001b[39mcv2\u001b[39m.\u001b[39mINTER_CUBIC, borderMode\u001b[39m=\u001b[39mcv2\u001b[39m.\u001b[39mBORDER_REPLICATE)\n\u001b[0;32m     40\u001b[0m     x, y \u001b[39m=\u001b[39m box\u001b[39m.\u001b[39mmin(axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m---> 41\u001b[0m     result[y:y\u001b[39m+\u001b[39;49mheight, x:x\u001b[39m+\u001b[39;49mwidth] \u001b[39m=\u001b[39m rotated\n\u001b[0;32m     43\u001b[0m text \u001b[39m=\u001b[39m pytesseract\u001b[39m.\u001b[39mimage_to_string(result, lang\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39meng\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     45\u001b[0m cv2\u001b[39m.\u001b[39mimshow(\u001b[39m\"\u001b[39m\u001b[39mRotated text\u001b[39m\u001b[39m\"\u001b[39m, result)\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (229,429,3) into shape (1,0,3)"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\python37\\pytesseract\\tesseract.exe'\n",
    "\n",
    "\n",
    "\n",
    "img = cv2.imread(\"image.jpg\")\n",
    "\n",
    "\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "thresh = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "contours = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "\n",
    "result = np.zeros_like(img)\n",
    "\n",
    "for i, contour in enumerate(contours):\n",
    "    rect = cv2.minAreaRect(contour)\n",
    "    box = cv2.boxPoints(rect)\n",
    "    box = np.int0(box)\n",
    "\n",
    "    ang = rect[-1]\n",
    "\n",
    "    if ang < -45:\n",
    "        ang = (180 + ang)\n",
    "    else:\n",
    "        ang = -ang\n",
    "\n",
    "    width = int(rect[1][0])\n",
    "    height = int(rect[1][1])\n",
    "\n",
    "    center = (int(rect[0][0]), int(rect[0][1]))\n",
    "\n",
    "    rotationMatrix = cv2.getRotationMatrix2D(center, ang, 1.0)\n",
    "\n",
    "    rotated = cv2.warpAffine(img, rotationMatrix, (width, height), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "\n",
    "    x, y = box.min(axis=0)\n",
    "    result[y:y+height, x:x+width] = rotated\n",
    "\n",
    "text = pytesseract.image_to_string(result, lang='eng')\n",
    "\n",
    "cv2.imshow(\"Rotated text\", result)\n",
    "print(text)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "img = cv2.imread('pra1.jpg')\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Threshold the image to get a binary image\n",
    "_, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "\n",
    "# Find contours in the image\n",
    "contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Loop over the contours\n",
    "for cnt in contours:\n",
    "    # Get the bounding box of the contour\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "    \n",
    "    # Extract the character from the image\n",
    "    character = gray[y:y+h, x:x+w]\n",
    "    \n",
    "    # Rotate the character\n",
    "    angle = -20\n",
    "    rot_mat = cv2.getRotationMatrix2D((w//2, h//2), angle, 1.0)\n",
    "    rotated = cv2.warpAffine(character, rot_mat, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "    \n",
    "    # Convert the rotated character to a 3-channel image\n",
    "    rotated = cv2.cvtColor(rotated, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    # Paste the rotated character back into the image\n",
    "    img[y:y+h, x:x+w] = rotated\n",
    "\n",
    "# Show the result\n",
    "cv2.imshow('Result', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3)\n",
      "[[ 0.70710677 -0.70710677  0.        ]\n",
      " [ 0.70710677  0.70710677  0.        ]\n",
      " [ 0.          0.          1.        ]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 9 into shape (2,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[39mprint\u001b[39m(M\u001b[39m.\u001b[39mshape)\n\u001b[0;32m     20\u001b[0m \u001b[39mprint\u001b[39m(M)\n\u001b[1;32m---> 21\u001b[0m M \u001b[39m=\u001b[39m M\u001b[39m.\u001b[39;49mreshape((\u001b[39m2\u001b[39;49m, \u001b[39m3\u001b[39;49m))\n\u001b[0;32m     23\u001b[0m \u001b[39m# Apply the transformation\u001b[39;00m\n\u001b[0;32m     24\u001b[0m rows, cols \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mshape[:\u001b[39m2\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 9 into shape (2,3)"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "img = cv2.imread('pra1.jpg')\n",
    "\n",
    "# Verify that the input image is not empty or None\n",
    "assert img is not None, \"Input image is empty or None\"\n",
    "\n",
    "# Verify that the input image has non-zero dimensions\n",
    "assert img.shape[0] > 0 and img.shape[1] > 0, \"Input image has zero dimensions\"\n",
    "\n",
    "# Define the transformation matrix (rotate by 45 degrees)\n",
    "theta = np.pi/4\n",
    "M = np.array([[np.cos(theta), -np.sin(theta), 0],\n",
    "              [np.sin(theta), np.cos(theta), 0],\n",
    "              [0, 0, 1]], dtype=np.float32)\n",
    "\n",
    "print(M.shape)\n",
    "print(M)\n",
    "M = M.reshape((2, 3))\n",
    "\n",
    "# Apply the transformation\n",
    "rows, cols = img.shape[:2]\n",
    "dst = cv2.warpAffine(img, M, (cols, rows))\n",
    "\n",
    "# Display the original and transformed images\n",
    "cv2.imshow('Original', img)\n",
    "cv2.imshow('Transformed', dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv conversion\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread('pra.jpg', 0)\n",
    "\n",
    "# Convert image to matrix\n",
    "img_mat = np.matrix(img)\n",
    "\n",
    "# Save matrix as CSV file\n",
    "df = pd.DataFrame(img_mat)\n",
    "df.to_csv('image.csv', index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\python37\\pytesseract\\tesseract.exe'\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"pra1.jpg\")\n",
    "\n",
    "# Convert to grayscale\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Threshold the image\n",
    "thresh = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[0]\n",
    "\n",
    "# Find contours of text regions\n",
    "contours = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "\n",
    "for i, contour in enumerate(contours):\n",
    "    print(f\"Contour {i+1}: {contour}\")\n",
    "\n",
    "\n",
    "# # Rotate each text region\n",
    "# for contour in contours:\n",
    "#     # Get the principal axis of the contour\n",
    "#     (x, y), (MA, ma), angle = cv2.fitEllipse(contour)\n",
    "\n",
    "    \n",
    "    \n",
    "#     # Negate the angle if it is greater than -45 degrees\n",
    "#     if angle < -45:\n",
    "#         angle = (angle)\n",
    "#     else:\n",
    "#         angle = (angle)\n",
    "\n",
    "#     print(f\"Angle: {angle}\")\n",
    "\n",
    "#     # Get the height and width of the rectangle\n",
    "#     width = int(ma)\n",
    "#     height = int(MA)\n",
    "\n",
    "#     # Get the center of the rectangle\n",
    "#     center = (int(x), int(y))\n",
    "\n",
    "#     # Get the rotation matrix\n",
    "#     rotationMatrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "\n",
    "#     # Rotate the text region\n",
    "#     rotated = cv2.warpAffine(img, rotationMatrix, (width, height), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "\n",
    "#     # Perform OCR on the rotated image to get the text\n",
    "#     text = pytesseract.image_to_string(rotated, lang='eng')\n",
    "\n",
    "    \n",
    "\n",
    "#     # Display the rotated text and the original contour\n",
    "#     cv2.drawContours(img, [contour], 0, (0, 0, 255), 2)\n",
    "#     cv2.imshow(\"Rotated text\", rotated)\n",
    "#     cv2.imshow(\"Original contour\", img)\n",
    "#     cv2.waitKey(0)\n",
    "\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tanish's\\AppData\\Local\\Temp\\ipykernel_756\\907713391.py:23: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n",
      "  box = np.int0(box)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting coordinates of contour: [15 86]\n",
      "Starting coordinates of contour: [28 85]\n",
      "Starting coordinates of contour: [46 78]\n",
      "Starting coordinates of contour: [58 69]\n",
      "Starting coordinates of contour: [71 68]\n",
      "Starting coordinates of contour: [81 59]\n",
      "Starting coordinates of contour: [104  55]\n",
      "Starting coordinates of contour: [121  48]\n",
      "Starting coordinates of contour: [134  43]\n",
      "Starting coordinates of contour: [149  37]\n",
      "Starting coordinates of contour: [165  31]\n",
      "Starting coordinates of contour: [183  19]\n",
      "Starting coordinates of contour: [200  17]\n",
      "Starting coordinates of contour: [214  11]\n"
     ]
    }
   ],
   "source": [
    "# contour starting coordinates\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\python37\\pytesseract\\tesseract.exe'\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"pra1.jpg\")\n",
    "\n",
    "# Convert to grayscale\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Threshold the image\n",
    "thresh = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "# Find contours of text regions\n",
    "contours = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "\n",
    "# for contour in contours:\n",
    "    # Get the minimum area rectangle that fits around the contour\n",
    "for i, contour in enumerate(contours):\n",
    "    rect = cv2.minAreaRect(contour)\n",
    "    box = cv2.boxPoints(rect)\n",
    "    box = np.int0(box)\n",
    "    cv2.drawContours(img, [box], 0, (0, 0, 255), 2)\n",
    "    # print(f\"Contour {i+1}: {contour}\"\n",
    "    # Get the starting coordinates of the contour\n",
    "    start_coord = contour[0][0]\n",
    "    print(f\"Starting coordinates of contour: {start_coord}\")\n",
    " \n",
    "    \n",
    "    cv2.imshow(\"Original contour\", img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounding box coordinates: Top-left: (7, 86), Bottom-right: (18, 102)\n",
      "Bounding box coordinates: Top-left: (26, 85), Bottom-right: (37, 97)\n",
      "Bounding box coordinates: Top-left: (42, 78), Bottom-right: (54, 90)\n",
      "Bounding box coordinates: Top-left: (57, 69), Bottom-right: (64, 84)\n",
      "Bounding box coordinates: Top-left: (69, 68), Bottom-right: (78, 80)\n",
      "Bounding box coordinates: Top-left: (81, 59), Bottom-right: (95, 74)\n",
      "Bounding box coordinates: Top-left: (100, 55), Bottom-right: (112, 71)\n",
      "Bounding box coordinates: Top-left: (117, 48), Bottom-right: (123, 61)\n",
      "Bounding box coordinates: Top-left: (130, 43), Bottom-right: (141, 55)\n",
      "Bounding box coordinates: Top-left: (147, 37), Bottom-right: (157, 49)\n",
      "Bounding box coordinates: Top-left: (162, 31), Bottom-right: (173, 43)\n",
      "Bounding box coordinates: Top-left: (178, 19), Bottom-right: (190, 36)\n",
      "Bounding box coordinates: Top-left: (195, 17), Bottom-right: (206, 29)\n",
      "Bounding box coordinates: Top-left: (211, 11), Bottom-right: (216, 23)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"pra1.jpg\")\n",
    "\n",
    "# Convert to grayscale\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Threshold the image\n",
    "thresh = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "# Find contours of text regions\n",
    "contours = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "\n",
    "# Draw bounding boxes around each contour\n",
    "for contour in contours:\n",
    "    # Get the minimum area rectangle that fits around the contour\n",
    "    x,y,w,h = cv2.boundingRect(contour)\n",
    "    \n",
    "    # Draw the bounding box on the image\n",
    "    cv2.rectangle(img, (x,y), (x+w,y+h), (0, 255, 0), 2)\n",
    "    \n",
    "    # Print the top-left corner coordinates of the bounding box\n",
    "    print(f\"Bounding box coordinates: Top-left: ({x}, {y}), Bottom-right: ({x+w}, {y+h})\")\n",
    "\n",
    "cv2.imshow(\"Bounding boxes\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounding box: Top-left: (7, 86), Bottom-right: (18, 102)\n",
      "Bounding box: Top-left: (26, 85), Bottom-right: (37, 97)\n",
      "Bounding box: Top-left: (42, 78), Bottom-right: (54, 90)\n",
      "Bounding box: Top-left: (57, 69), Bottom-right: (64, 84)\n",
      "Bounding box: Top-left: (69, 68), Bottom-right: (78, 80)\n",
      "Bounding box: Top-left: (81, 59), Bottom-right: (95, 74)\n",
      "Bounding box: Top-left: (100, 55), Bottom-right: (112, 71)\n",
      "Bounding box: Top-left: (117, 48), Bottom-right: (123, 61)\n",
      "Bounding box: Top-left: (130, 43), Bottom-right: (141, 55)\n",
      "Bounding box: Top-left: (147, 37), Bottom-right: (157, 49)\n",
      "Bounding box: Top-left: (162, 31), Bottom-right: (173, 43)\n",
      "Bounding box: Top-left: (178, 19), Bottom-right: (190, 36)\n",
      "Bounding box: Top-left: (195, 17), Bottom-right: (206, 29)\n",
      "Bounding box: Top-left: (211, 11), Bottom-right: (216, 23)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\python37\\pytesseract\\tesseract.exe'\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"pra1.jpg\")\n",
    "\n",
    "# Convert to grayscale\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Threshold the image\n",
    "thresh = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "# Find contours of text regions\n",
    "contours = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "\n",
    "# Draw bounding boxes around each contour\n",
    "for contour in contours:\n",
    "    # Get the bounding rectangle of the contour\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "    # Draw the bounding box on the image\n",
    "    cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Print the pixel values of the top-left and bottom-right corners of the bounding box\n",
    "    print(f\"Bounding box: Top-left: ({x}, {y}), Bottom-right: ({x + w}, {y + h})\")\n",
    "\n",
    "# Show the image with bounding boxes\n",
    "cv2.imshow(\"Image with bounding boxes\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contour pixel values to new csv file\n",
    "import cv2\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"pra1.jpg\")\n",
    "\n",
    "# Convert to grayscale\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Threshold the image\n",
    "thresh = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "# Find contours of text regions\n",
    "contours = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "\n",
    "# Initialize list to store all contour pixel values\n",
    "contour_pixels = []\n",
    "\n",
    "# Process each contour\n",
    "for i, contour in enumerate(contours):\n",
    "    # Get the bounding box coordinates\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "    \n",
    "    # Extract the pixel values of the bounding box region\n",
    "    box_pixels = img[y:y+h, x:x+w]\n",
    "    \n",
    "    # Append the pixel values to the list\n",
    "    contour_pixels.append(box_pixels)\n",
    "    \n",
    "    # Draw the bounding box on the image\n",
    "    cv2.rectangle(img, (x,y), (x+w,y+h), (0, 255, 0), 2)\n",
    "\n",
    "# Write the pixel values of all contours to a CSV file\n",
    "with open(\"contours.csv\", \"w\", newline=\"\") as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    for pixels in contour_pixels:\n",
    "        for row in pixels:\n",
    "            writer.writerow(row)\n",
    "\n",
    "# Show the image with bounding boxes\n",
    "cv2.imshow(\"Bounding boxes\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tanish's\\AppData\\Local\\Temp\\ipykernel_13988\\1403013555.py:23: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n",
      "  box = np.int0(box)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounding box: Top-left: (29, 89), Bottom-right: (35, 96), Angle: 90.0\n",
      "Bounding box: Top-left: (7, 86), Bottom-right: (18, 102), Angle: 90.0\n",
      "Bounding box: Top-left: (26, 85), Bottom-right: (37, 97), Angle: 90.0\n",
      "Bounding box: Top-left: (42, 78), Bottom-right: (54, 90), Angle: 90.0\n",
      "Bounding box: Top-left: (57, 69), Bottom-right: (64, 84), Angle: 90.0\n",
      "Bounding box: Top-left: (69, 68), Bottom-right: (78, 80), Angle: 90.0\n",
      "Bounding box: Top-left: (81, 59), Bottom-right: (95, 74), Angle: 90.0\n",
      "Bounding box: Top-left: (102, 56), Bottom-right: (110, 65), Angle: 90.0\n",
      "Bounding box: Top-left: (100, 55), Bottom-right: (112, 71), Angle: 90.0\n",
      "Bounding box: Top-left: (117, 48), Bottom-right: (123, 61), Angle: 90.0\n",
      "Bounding box: Top-left: (131, 44), Bottom-right: (140, 54), Angle: 90.0\n",
      "Bounding box: Top-left: (130, 43), Bottom-right: (141, 55), Angle: 90.0\n",
      "Bounding box: Top-left: (147, 37), Bottom-right: (157, 49), Angle: 90.0\n",
      "Bounding box: Top-left: (163, 32), Bottom-right: (171, 42), Angle: 90.0\n",
      "Bounding box: Top-left: (162, 31), Bottom-right: (173, 43), Angle: 90.0\n",
      "Bounding box: Top-left: (180, 25), Bottom-right: (188, 35), Angle: 90.0\n",
      "Bounding box: Top-left: (196, 18), Bottom-right: (203, 24), Angle: 90.0\n",
      "Bounding box: Top-left: (178, 19), Bottom-right: (190, 36), Angle: 90.0\n",
      "Bounding box: Top-left: (195, 17), Bottom-right: (206, 29), Angle: 90.0\n",
      "Bounding box: Top-left: (211, 11), Bottom-right: (216, 23), Angle: 90.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\python37\\pytesseract\\tesseract.exe'\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"pra1.jpg\")\n",
    "\n",
    "# Convert to grayscale\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Threshold the image\n",
    "thresh = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "# Find contours of text regions\n",
    "contours = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "\n",
    "# Draw bounding boxes around each contour\n",
    "for contour in contours:\n",
    "    # Get the bounding rectangle of the contour\n",
    "    rect = cv2.minAreaRect(contour)\n",
    "    box = cv2.boxPoints(rect)\n",
    "    box = np.int0(box)\n",
    "\n",
    "    # Draw the bounding box on the image\n",
    "    cv2.drawContours(img, [box], 0, (0, 255, 0), 2)\n",
    "    \n",
    "\n",
    "    # Get the coordinates of the bounding box\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "    # # Get the angle of rotation\n",
    "    # angle = rect[-1]\n",
    "\n",
    "    # Print the bounding box coordinates and angle of rotation\n",
    "    print(f\"Bounding box: Top-left: ({x}, {y}), Bottom-right: ({x + w}, {y + h}), Angle: {angle}\")\n",
    "\n",
    "# Show the image with bounding boxes\n",
    "cv2.imshow(\"Image with bounding boxes\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tanish's\\AppData\\Local\\Temp\\ipykernel_13988\\162421487.py:23: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n",
      "  box = np.int0(box)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounding box 1: Top-left: (7, 86), Bottom-right: (18, 102), Angle: 90.0\n",
      "Bounding box 2: Top-left: (26, 85), Bottom-right: (37, 97), Angle: 71.56504821777344\n",
      "Bounding box 3: Top-left: (42, 78), Bottom-right: (54, 90), Angle: 68.19859313964844\n",
      "Bounding box 4: Top-left: (57, 69), Bottom-right: (64, 84), Angle: 68.19859313964844\n",
      "Bounding box 5: Top-left: (69, 68), Bottom-right: (78, 80), Angle: 66.80140686035156\n",
      "Bounding box 6: Top-left: (81, 59), Bottom-right: (95, 74), Angle: 68.19859313964844\n",
      "Bounding box 7: Top-left: (100, 55), Bottom-right: (112, 71), Angle: 68.19859313964844\n",
      "Bounding box 8: Top-left: (117, 48), Bottom-right: (123, 61), Angle: 5.194429397583008\n",
      "Bounding box 9: Top-left: (130, 43), Bottom-right: (141, 55), Angle: 90.0\n",
      "Bounding box 10: Top-left: (147, 37), Bottom-right: (157, 49), Angle: 66.80140686035156\n",
      "Bounding box 11: Top-left: (162, 31), Bottom-right: (173, 43), Angle: 90.0\n",
      "Bounding box 12: Top-left: (178, 19), Bottom-right: (190, 36), Angle: 68.19859313964844\n",
      "Bounding box 13: Top-left: (195, 17), Bottom-right: (206, 29), Angle: 71.56504821777344\n",
      "Bounding box 14: Top-left: (211, 11), Bottom-right: (216, 23), Angle: 90.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\python37\\pytesseract\\tesseract.exe'\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"pra1.jpg\")\n",
    "\n",
    "# Convert to grayscale\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Threshold the image\n",
    "thresh = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "# Find contours of text regions\n",
    "contours = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "\n",
    "# Draw bounding boxes around each contour\n",
    "for i, contour in enumerate(contours):\n",
    "    # Get the bounding rectangle of the contour\n",
    "    rect = cv2.minAreaRect(contour)\n",
    "    box = cv2.boxPoints(rect)\n",
    "    box = np.int0(box)\n",
    "\n",
    "    # Draw the bounding box on the image\n",
    "    cv2.drawContours(img, [box], 0, (0, 255, 0), 2)\n",
    "\n",
    "    # Get the coordinates of the bounding box\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "    # Get the angle of rotation\n",
    "    angle = rect[-1]\n",
    "\n",
    "    # Print the bounding box coordinates and angle of rotation\n",
    "    print(f\"Bounding box {i+1}: Top-left: ({x}, {y}), Bottom-right: ({x + w}, {y + h}), Angle: {angle}\")\n",
    "\n",
    "    # Rotate the first contour by 30 degrees\n",
    "    if i == 0:\n",
    "        rows, cols = gray_img.shape[:2]\n",
    "        M = cv2.getRotationMatrix2D(rect[0], 30, 1)\n",
    "        rotated_img = cv2.warpAffine(gray_img, M, (cols, rows))\n",
    "\n",
    "# Show the original image with bounding boxes\n",
    "cv2.imshow(\"Original image with bounding boxes\", img)\n",
    "\n",
    "# Show the rotated image\n",
    "cv2.imshow(\"Rotated image\", rotated_img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-90.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img=cv2.imread(\"image.jpg\")\n",
    "cv2.imshow(\"orignal image\",img)\n",
    "cv2.waitKey(0)\n",
    "gray_img= cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "grey_img= cv2.bitwise_not(gray_img)\n",
    "coordinates = np.column_stack(np.where(gray_img >0))\n",
    "ang =cv2.minAreaRect(coordinates)[-1]\n",
    "if ang <-45:\n",
    "    ang= -(90 +ang)\n",
    "else:\n",
    "    ang = -(ang)\n",
    "print(ang)\n",
    "height, width =img.shape[:2]\n",
    "center_img =(width/2 , height/2)\n",
    "rotationMatrix= cv2.getRotationMatrix2D(center_img,ang,1.0)\n",
    "rotated_img = cv2.warpAffine(img,rotationMatrix,(width+30,height ), borderMode=cv2.BORDER_REFLECT )\n",
    "cv2.imshow(\"Rotated Image \", rotated_img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('pra1.jpg')\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "thresh = cv2.adaptiveThreshold(gray,255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11,2)\n",
    "\n",
    "kernel = np.ones((3,3), np.uint8)\n",
    "\n",
    "closing = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel , iterations=2)\n",
    "opening = cv2.morphologyEx(closing, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "\n",
    "denoised = cv2.fastNlMeansDenoising(opening, None, 5,7,21)\n",
    "\n",
    "cv2.imshow(\"denoised\", opening)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread('OIP.jpg', 0)\n",
    "\n",
    "# Convert image to matrix\n",
    "img_mat = np.matrix(img)\n",
    "\n",
    "# Save matrix as CSV file\n",
    "df = pd.DataFrame(img_mat)\n",
    "df.to_csv('OIP.csv', index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from PIL import Image\n",
    "\n",
    "# Open CSV file\n",
    "with open('image_up.csv', 'r') as csvfile:\n",
    "    # Create CSV reader object\n",
    "    csvreader = csv.reader(csvfile)\n",
    "    \n",
    "    # Read pixel values from CSV file\n",
    "    pixel_values = []\n",
    "    for row in csvreader:\n",
    "        if row:\n",
    "            pixel_values.append([int(x) for x in row])\n",
    "    \n",
    "    # Convert pixel values to image\n",
    "    img = Image.new('L', (len(pixel_values[0]), len(pixel_values)))\n",
    "    for y in range(len(pixel_values)):\n",
    "        for x in range(len(pixel_values[0])):\n",
    "            img.putpixel((x, y), pixel_values[y][x])\n",
    "    \n",
    "    # Save image to file\n",
    "    img.save('output2.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(\u001b[39m\"\u001b[39m\u001b[39mOIP2.jpg\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[39m# Convert to grayscale\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m gray_img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mcvtColor(img, cv2\u001b[39m.\u001b[39;49mCOLOR_BGR2GRAY)\n\u001b[0;32m     13\u001b[0m \u001b[39m# Threshold the image\u001b[39;00m\n\u001b[0;32m     14\u001b[0m thresh \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mthreshold(gray_img, \u001b[39m0\u001b[39m, \u001b[39m255\u001b[39m, cv2\u001b[39m.\u001b[39mTHRESH_BINARY_INV \u001b[39m+\u001b[39m cv2\u001b[39m.\u001b[39mTHRESH_OTSU)[\u001b[39m1\u001b[39m]\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\python37\\pytesseract\\tesseract.exe'\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"OIP2.jpg\")\n",
    "\n",
    "# Convert to grayscale\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Threshold the image\n",
    "thresh = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "# print(thresh)\n",
    "\n",
    "# Find contours of text regions\n",
    "\n",
    "contours = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)[0]\n",
    "\n",
    "# # Sort the contours by their x-coordinates\n",
    "contours = sorted(contours, key=lambda c:cv2.boundingRect(c)[0] ,reverse= False)\n",
    "\n",
    "# # print(contours)\n",
    "# # Calculate the center of mass of each contour\n",
    "# Create a new blank image with the same size as the input image\n",
    "contour_img = np.zeros_like(img)\n",
    "\n",
    "# Sort the contours by area in descending order\n",
    "# contours = sorted(contours, key=cv2.contourArea,)\n",
    "\n",
    "# Calculate the average height of the contours\n",
    "heights = [cv2.boundingRect(c)[3] for c in contours]\n",
    "avg_height = sum(heights) // len(heights)\n",
    "\n",
    "# Create a list to store the extracted regions\n",
    "regions = [contour_img]\n",
    "\n",
    "# Adjust the x-coordinates of the contours to align them horizontally\n",
    "x_offset = 0\n",
    "for contour in contours:\n",
    "    # Get the bounding rectangle of the contour\n",
    "    rect = cv2.minAreaRect(contour)\n",
    "    box = cv2.boxPoints(rect)\n",
    "    box = np.int0(box)\n",
    "    # cv2.drawContours(img, [box], 0, (0, 0, 255), 2)\n",
    "\n",
    "    # Adjust the x-coordinate of the bounding box\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "    x += x_offset\n",
    "    x_offset += h  # Increment the x offset for the next contour\n",
    "\n",
    "    # Adjust the y-coordinate of the bounding box to center it vertically\n",
    "    y += (avg_height - h) // 2\n",
    "\n",
    "    # Extract the region corresponding to the contour\n",
    "    region = gray_img[y:x+h, x:y+w]\n",
    "\n",
    "    # Add the region to the list of extracted regions\n",
    "    regions.append(region)\n",
    "\n",
    "    # cv2.imshow(\"regions\" , regions)\n",
    "\n",
    "    # Get the angle of rotation\n",
    "    angle = rect[-1]\n",
    "    z = 1\n",
    "    # Print the bounding box coordinates and angle of rotation\n",
    "    \n",
    "# print(  f\"Bounding box: Top-left: ({x}, {y}), Bottom-right: ({x + w}, {y + h}), Angle: {angle}\" )\n",
    "\n",
    "# Create a new image with the extracted regions aligned horizontally\n",
    "aligned_regions = []\n",
    "\n",
    "for contour in contours:\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "    # Resize the region to have the same height as the average height\n",
    "    resized_region = cv2.resize(thresh[y:y+h, x:x+w], (w, avg_height))\n",
    "\n",
    "    # Append the resized region to the list of aligned regions\n",
    "    aligned_regions.append(resized_region)\n",
    "\n",
    "# Concatenate the aligned regions horizontally\n",
    "aligned_regions = np.hstack(aligned_regions)\n",
    "\n",
    "# print(regions)\n",
    "\n",
    "cv2.imshow(\"cony\", img)\n",
    "\n",
    "# Show the aligned regions\n",
    "cv2.imwrite(\"alligned.jpg\" , aligned_regions)\n",
    "cv2.imshow(\"Aligned Regions\", aligned_regions)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image and find contours\n",
    "img = cv2.imread('pra1.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "ret, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Sort the contours by area in descending order\n",
    "contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "\n",
    "# Create a list to hold the extracted contour images\n",
    "contour_images = []\n",
    "\n",
    "# Iterate over the sorted contours and extract each one as an image\n",
    "for contour in contours:\n",
    "    # Create a mask image for the contour\n",
    "    mask = np.zeros_like(gray)\n",
    "    cv2.drawContours(mask, [contour], 0, 255, -1)\n",
    "\n",
    "    # Extract the contour from the original image using the mask\n",
    "    contour_img = cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "    # Add the extracted contour image to the list\n",
    "    contour_images.append(contour_img)\n",
    "\n",
    "# Concatenate the contour images horizontally to form a new image\n",
    "new_img = np.concatenate(contour_images, axis=1)\n",
    "\n",
    "# Display the new image\n",
    "cv2.imshow('Contours', new_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import inspect\n",
    "\n",
    "# lines = inspect.getsourcelines(contours)\n",
    "# print(lines)\n",
    "\n",
    "\n",
    "# Load the image and find contours\n",
    "img = cv2.imread('pra1.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "ret, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# for cont in contours:\n",
    "#     cv2.drawContours(contour_img, cont, -1, (0, 255, 0), 3)\n",
    "#     cv2.imshow('Contours', contour_img)\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()\n",
    "#     area = cv2.contourArea(cont)\n",
    "#     x,y,w,h = cv2.boundingRect(cont)\n",
    "#     angle = cv2.fitEllipse(cont)\n",
    "    # print(angle)\n",
    "    # print(\"width and height of\",w,h)\n",
    "    # print(\"area of\",area)\n",
    "\n",
    "# Create a new blank image with the same size as the input image\n",
    "contour_img = np.zeros_like(img)\n",
    "\n",
    "# Sort the contours by area in descending order\n",
    "#contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "\n",
    "# Draw the contours on the new image in the sorted order\n",
    "for contour in contours:\n",
    "    cv2.drawContours(contour_img, [contour], -1, (255, 255, 255), 2)\n",
    "\n",
    "# Display the new image\n",
    "cv2.imshow('Contours', contour_img)\n",
    "cv2.imwrite('repo1.jpg',contour_img )\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image and find contours\n",
    "img = cv2.imread('OIP.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "ret, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Sort the contours by x-coordinate\n",
    "contours = sorted(contours, key=lambda c: cv2.boundingRect(c)[0])\n",
    "\n",
    "# Create a new blank image with the same height as the input image and width equal to the sum of the widths of all contours\n",
    "# new_width = sum(cv2.boundingRect(c)[2] for c in contours)\n",
    "# new_height = img.shape[0]\n",
    "# contour_img = np.zeros((new_height, new_width, 3), np.uint8)\n",
    "\n",
    "# Iterate over the contours, draw each contour on the new image, and update the x-coordinate for the next contour\n",
    "x_offset = 0\n",
    "for contour in contours:\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "    cv2.drawContours(contour_img, [contour], -1, (255, 255, 255), -1)\n",
    "    x_offset += w\n",
    "\n",
    "# Display the new image with\n",
    "cv2.imshow('Contours', contour_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tanish's\\AppData\\Local\\Temp\\ipykernel_13988\\3939334411.py:37: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n",
      "  box = np.int0(box)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\python37\\pytesseract\\tesseract.exe'\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"pra1.jpg\")\n",
    "\n",
    "# Convert to grayscale\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Threshold the image\n",
    "thresh = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "# Find contours of text regions\n",
    "\n",
    "contours = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "# print(contours)s\n",
    "\n",
    "# Sort the contours by their x-coordinates\n",
    "# contours = sorted(contours, key=lambda c: cv2.boundingRect(c)[0])\n",
    "\n",
    "# Calculate the average height of the contours\n",
    "heights = [cv2.boundingRect(c)[3] for c in contours]\n",
    "avg_height = sum(heights) // len(heights)\n",
    "\n",
    "# Create a list to store the extracted regions\n",
    "regions = []\n",
    "\n",
    "# Adjust the x-coordinates of the contours to align them horizontally\n",
    "x_offset = 0\n",
    "for contour in contours:\n",
    "    # Get the bounding rectangle of the contour\n",
    "    rect = cv2.minAreaRect(contour)\n",
    "    box = cv2.boxPoints(rect)\n",
    "    box = np.int0(box)\n",
    "\n",
    "    # Adjust the x-coordinate of the bounding box\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "    x += x_offset\n",
    "    x_offset += w  # Increment the x offset for the next contour\n",
    "\n",
    "    # Adjust the y-coordinate of the bounding box to center it vertically\n",
    "    # y += (avg_height - h) // 2\n",
    "\n",
    "    # Extract the region corresponding to the contour\n",
    "    region = gray_img[y:y+h, x:x+w]\n",
    "\n",
    "    # Add the region to the list of extracted regions\n",
    "    regions.append(region)\n",
    "\n",
    "    # Get the angle of rotation\n",
    "    angle = rect[-1]\n",
    "    z = 1\n",
    "    # Print the bounding box coordinates and angle of rotation\n",
    "    \n",
    "#    print(  f\"Bounding box: Top-left: ({x}, {y}), Bottom-right: ({x + w}, {y + h}), Angle: {angle}\" )\n",
    "\n",
    "# Create a new image with the extracted regions aligned horizontally\n",
    "aligned_regions = []\n",
    "for contour in contours:\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "    # Resize the region to have the same height as the average height\n",
    "    resized_region = cv2.resize(thresh[y:y+h, x:x+w], (w, avg_height))\n",
    "\n",
    "    # Append the resized region to the list of aligned regions\n",
    "    aligned_regions.append(resized_region)\n",
    "\n",
    "# Concatenate the aligned regions horizontally\n",
    "aligned_regions = np.hstack(aligned_regions)\n",
    "\n",
    "# Show the aligned regions\n",
    "cv2.imwrite(\"alligned.jpg\" , aligned_regions)\n",
    "cv2.imshow(\"Aligned Regions\", aligned_regions)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 142)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"pra1.png\")\n",
    "\n",
    "# Convert to grayscale\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Threshold the image\n",
    "thresh = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "# Find contours of text regions\n",
    "contours = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "\n",
    "# Sort the contours by their y-coordinates\n",
    "contours = sorted(contours, key=lambda c: cv2.boundingRect(c)[1] ,reverse = False)\n",
    "\n",
    "# Create a list to store the extracted regions\n",
    "regions = []\n",
    "\n",
    "# Extract and resize the regions\n",
    "max_height = 0\n",
    "for contour in contours:\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "    region = gray_img[y:y+h, x:x+w]\n",
    "    max_height = max(max_height, h)\n",
    "    regions.append(region)\n",
    "\n",
    "for i in range(len(regions)):\n",
    "    regions[i] = cv2.resize(regions[i], (regions[i].shape[1], max_height))\n",
    "\n",
    "# Horizontally stack the regions of each line\n",
    "line_images = []\n",
    "line_regions = []\n",
    "prev_y = None\n",
    "for contour, region in zip(contours, regions):\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "    if prev_y is None or y - prev_y > max_height:\n",
    "        if line_regions:\n",
    "            line_image = np.hstack(line_regions)\n",
    "            line_images.append(line_image)\n",
    "        line_regions = [region]\n",
    "    else:\n",
    "        line_regions.append(region)\n",
    "    prev_y = y\n",
    "\n",
    "if line_regions:\n",
    "\n",
    "\n",
    "    line_image = np.hstack(line_regions)\n",
    "    line_images.append(line_image)\n",
    "\n",
    "for line_image in line_images:\n",
    "    print(line_image.shape)\n",
    "\n",
    "# Find the maximum width and height among all the regions\n",
    "max_width = max(region.shape[1] for region in regions)\n",
    "max_height = max(region.shape[0] for region in regions)\n",
    "\n",
    "# Pad the shorter regions with zeros to make them the same size\n",
    "padded_regions = []\n",
    "for region in regions:\n",
    "    h_diff = max_height - region.shape[0]\n",
    "    w_diff = max_width - region.shape[1]\n",
    "    top = h_diff // 2\n",
    "    bottom = h_diff - top\n",
    "    left = w_diff // 2\n",
    "    right = w_diff - left\n",
    "    padded_region = cv2.copyMakeBorder(region, top, bottom, left, right, cv2.BORDER_CONSTANT, value=0)\n",
    "    padded_regions.append(padded_region)\n",
    "\n",
    "# Concatenate the padded regions vertically using cv2.vconcat\n",
    "result = cv2.vconcat(padded_regions)\n",
    "# result - cv2.hconcat(padded_regions)\n",
    "\n",
    "# Show the result\n",
    "cv2.imshow(\"Result\", result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2.text' has no attribute 'DETECT_ORIENTATION_REGULAR'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m er_filter2 \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mgetStructuringElement(cv2\u001b[39m.\u001b[39mMORPH_RECT, (\u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m))\n\u001b[0;32m     16\u001b[0m region_filters \u001b[39m=\u001b[39m [er_filter1, er_filter2]\n\u001b[1;32m---> 17\u001b[0m lines \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mtext\u001b[39m.\u001b[39mdetectRegions(thresh, region_filters, cv2\u001b[39m.\u001b[39;49mtext\u001b[39m.\u001b[39;49mDETECT_ORIENTATION_REGULAR, \u001b[39m1\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[39m# Initialize a list to store the extracted regions\u001b[39;00m\n\u001b[0;32m     20\u001b[0m regions \u001b[39m=\u001b[39m []\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2.text' has no attribute 'DETECT_ORIENTATION_REGULAR'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"OIP.jpg\")\n",
    "\n",
    "# Convert to grayscale\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Threshold the image\n",
    "thresh = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "# Split the image into lines\n",
    "er_filter1 = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 5))\n",
    "er_filter2 = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 1))\n",
    "region_filters = [er_filter1, er_filter2]\n",
    "lines = cv2.text.detectRegions(thresh, region_filters, cv2.text., 1)\n",
    "\n",
    "# Initialize a list to store the extracted regions\n",
    "regions = []\n",
    "\n",
    "for line in lines:\n",
    "    # Find contours in the line\n",
    "    contours = cv2.findContours(line, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "\n",
    "    # Sort the contours by their x-coordinate\n",
    "    contours = sorted(contours, key=lambda c: cv2.boundingRect(c)[0])\n",
    "\n",
    "    # Calculate the average height of the contours\n",
    "    heights = [cv2.boundingRect(c)[3] for c in contours]\n",
    "    avg_height = sum(heights) // len(heights)\n",
    "\n",
    "    # Create a list to store the extracted regions in this line\n",
    "    line_regions = []\n",
    "\n",
    "    # Align the regions horizontally and extract them\n",
    "    x_offset = 0\n",
    "    for contour in contours:\n",
    "        # Get the bounding box of the contour\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "        # Adjust the x-coordinate of the bounding box to align it horizontally\n",
    "        x += x_offset\n",
    "        x_offset += w\n",
    "\n",
    "        # Extract the region corresponding to the contour\n",
    "        region = gray_img[y:y+h, x:x+w]\n",
    "\n",
    "        # Resize the region to have the same height as the average height\n",
    "        resized_region = cv2.resize(region, (w, avg_height))\n",
    "\n",
    "        # Add the resized region to the list of extracted regions in this line\n",
    "        line_regions.append(resized_region)\n",
    "\n",
    "    # Concatenate the extracted regions horizontally\n",
    "    aligned_regions = np.hstack(line_regions)\n",
    "\n",
    "    # Add the aligned regions to the list of extracted regions\n",
    "    regions.append(aligned_regions)\n",
    "\n",
    "# Concatenate the aligned regions from each line vertically\n",
    "final_image = np.vstack(regions)\n",
    "\n",
    "# Show the final image\n",
    "cv2.imshow(\"Final Image\", final_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ... 255 255 179]\n",
      " [  0   0   0 ... 209 209   0]\n",
      " [  0   0   0 ...   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "\n",
    "\n",
    "def concatenate_horizontally(img_list):\n",
    "    # Get the maximum height of the images\n",
    "    max_height = max([img.shape[0] for img in img_list])\n",
    "\n",
    "    # Resize all images to the maximum height and concatenate them horizontally\n",
    "    resized_imgs = [cv2.resize(img, (int(img.shape[1] * max_height / img.shape[0]), max_height)) for img in img_list]\n",
    "    concatenated_img = np.concatenate(resized_imgs, axis=1)\n",
    "\n",
    "    return concatenated_img\n",
    "\n",
    "\n",
    "# Set Tesseract path\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\python37\\pytesseract\\tesseract.exe'\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"test2.jpg\")\n",
    "\n",
    "# Convert to grayscale\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Threshold the image\n",
    "thresh = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "# Find contours of text regions\n",
    "contours = sorted(cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0], key=lambda c: cv2.boundingRect(c)[0])\n",
    "\n",
    "# Sort the contours from top to bottom\n",
    "contours = sorted(contours, key=lambda c: cv2.boundingRect(c)[1])\n",
    "\n",
    "# Calculate the average height of the contours\n",
    "heights = [cv2.boundingRect(c)[3] for c in contours]\n",
    "avg_height = sum(heights) // len(heights)\n",
    "\n",
    "# Create a list to store the extracted regions\n",
    "regions = []\n",
    "\n",
    "# Extract the regions corresponding to the contours\n",
    "for contour in contours:\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "    # Resize the region to have the same height as the average height\n",
    "    resized_region = cv2.resize(thresh[y:y+h, x:x+w], (w, avg_height))\n",
    "\n",
    "    # Add the region to the list of extracted regions\n",
    "    regions.append(resized_region)\n",
    "\n",
    "# Concatenate the extracted regions horizontally\n",
    "aligned_regions = concatenate_horizontally(regions)\n",
    "\n",
    "print (aligned_regions)\n",
    "\n",
    "# Show the aligned regions\n",
    "cv2.imshow(\"Aligned Regions\", aligned_regions)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UPAR WALA 2 LINE TEXT KE SAATH SAHI WORK KR RAHA HAI BUT 3RD LINE MAI DIKKAT AA RAHI HAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "\n",
    "def concatenate_horizontally(img_list):\n",
    "    # Get the maximum height of the images\n",
    "    max_height = max([img.shape[0] for img in img_list])\n",
    "\n",
    "    # Resize all images to the maximum height and concatenate them horizontally\n",
    "    resized_imgs = [cv2.resize(img, (int(img.shape[1] * max_height / img.shape[0]), max_height)) for img in img_list]\n",
    "    concatenated_img = np.concatenate(resized_imgs, axis=1)\n",
    "\n",
    "    return concatenated_img\n",
    "\n",
    "# Set Tesseract path\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\python37\\pytesseract\\tesseract.exe'\n",
    "\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"test2.jpg\")\n",
    "\n",
    "# Convert to grayscale\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Threshold the image\n",
    "thresh = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "# Find contours of text regions\n",
    "contours = sorted(cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0], key=lambda c: cv2.boundingRect(c)[0])\n",
    "\n",
    "# Sort the contours from left to right\n",
    "contours = sorted(contours, key=lambda c: cv2.boundingRect(c)[0])\n",
    "\n",
    "# Calculate the average height of the contours\n",
    "heights = [cv2.boundingRect(c)[3] for c in contours]\n",
    "avg_height = sum(heights) // len(heights)\n",
    "\n",
    "# Create a list to store the extracted regions\n",
    "regions = []\n",
    "\n",
    "# Extract the regions corresponding to the contours\n",
    "for contour in contours:\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "    # Resize the region to have the same height as the average height\n",
    "    resized_region = cv2.resize(thresh[y:y+h, x:x+w], (w, avg_height))\n",
    "\n",
    "    # Add the region to the list of extracted regions\n",
    "    regions.append(resized_region)\n",
    "\n",
    "# Concatenate the extracted regions horizontally\n",
    "aligned_regions = concatenate_horizontally(regions)\n",
    "\n",
    "# Show the aligned regions\n",
    "cv2.imshow(\"Aligned Regions\", aligned_regions)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for text line segmentatio \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\layers\\convolution_layer.cpp:420: error: (-2:Unspecified error) Number of input channels should be multiple of 3 but got 1 in function 'cv::dnn::ConvolutionLayerImpl::getMemoryShapes'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m blob \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mdnn\u001b[39m.\u001b[39mblobFromImage(gray, \u001b[39m1.0\u001b[39m, (\u001b[39m320\u001b[39m, \u001b[39m320\u001b[39m), (\u001b[39m123.68\u001b[39m, \u001b[39m116.78\u001b[39m, \u001b[39m103.94\u001b[39m), \u001b[39mTrue\u001b[39;00m, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m     17\u001b[0m net\u001b[39m.\u001b[39msetInput(blob)\n\u001b[1;32m---> 18\u001b[0m scores, geometry \u001b[39m=\u001b[39m net\u001b[39m.\u001b[39;49mforward([\u001b[39m'\u001b[39;49m\u001b[39mfeature_fusion/Conv_7/Sigmoid\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mfeature_fusion/concat_3\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m     20\u001b[0m \u001b[39m# Extract the text regions from the image\u001b[39;00m\n\u001b[0;32m     21\u001b[0m rectangles \u001b[39m=\u001b[39m []\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\layers\\convolution_layer.cpp:420: error: (-2:Unspecified error) Number of input channels should be multiple of 3 but got 1 in function 'cv::dnn::ConvolutionLayerImpl::getMemoryShapes'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\python37\\pytesseract\\tesseract.exe'\n",
    "\n",
    "\n",
    "# Read the image\n",
    "img = cv2.imread('test2.jpg')\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Perform text detection using EAST text detector\n",
    "net = cv2.dnn.readNet('frozen_east_text_detection.pb')\n",
    "blob = cv2.dnn.blobFromImage(gray, 1.0, (320, 320), (123.68, 116.78, 103.94), True, False)\n",
    "net.setInput(blob)\n",
    "scores, geometry = net.forward(['feature_fusion/Conv_7/Sigmoid', 'feature_fusion/concat_3'])\n",
    "\n",
    "# Extract the text regions from the image\n",
    "rectangles = []\n",
    "confidences = []\n",
    "for i in range(geometry.shape[2]):\n",
    "    # Calculate the score and geometry of the text region\n",
    "    scores_data = scores[0][0][i]\n",
    "    x0 = geometry[0][0][i][0]\n",
    "    y0 = geometry[0][0][i][1]\n",
    "    x1 = geometry[0][0][i][2]\n",
    "    y1 = geometry[0][0][i][3]\n",
    "    angle = geometry[0][0][i][4]\n",
    "    if scores_data < 0.5:\n",
    "        continue\n",
    "\n",
    "    # Calculate the coordinates of the bounding box for the text region\n",
    "    h = y1 - y0\n",
    "    w = x1 - x0\n",
    "    x = x0 + w * np.cos(angle)\n",
    "    y = y0 + h * np.sin(angle)\n",
    "\n",
    "    # Append the bounding box coordinates and confidence score to the respective lists\n",
    "    rectangles.append((x, y, w, h, angle))\n",
    "    confidences.append(float(scores_data))\n",
    "\n",
    "# Sort the text regions by their confidence score\n",
    "indices = cv2.dnn.NMSBoxesRotated(rectangles, confidences, 0.5, 0.5)\n",
    "text_regions = []\n",
    "for i in indices:\n",
    "    rect = rectangles[i[0]]\n",
    "    x, y, w, h, angle = rect\n",
    "    # Crop the text region from the image\n",
    "    rotated = False\n",
    "    if angle < -45:\n",
    "        angle = -(90 + angle)\n",
    "        rotated = True\n",
    "    else:\n",
    "        angle = -angle\n",
    "    center = (int(x), int(y))\n",
    "    size = (int(w), int(h))\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    cropped = cv2.getRectSubPix(img, size, center)\n",
    "    cropped = cv2.warpAffine(cropped, M, size)\n",
    "    if rotated:\n",
    "        w, h = h, w\n",
    "    text_regions.append((cropped, rect, (x, y, w, h)))\n",
    "\n",
    "# Perform text recognition on each text region and\n",
    "recognized_text = ''\n",
    "for region in regions:\n",
    "# Perform text recognition on the region\n",
    "    text = pytesseract.image_to_string(region, lang='eng', config='--psm 6')\n",
    "    # Append the recognized text to the concatenated text\n",
    "    recognized_text += text.strip()\n",
    "print(recognized_text)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
