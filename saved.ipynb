{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tanish's\\AppData\\Local\\Temp\\ipykernel_912\\1711883975.py:37: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n",
      "  box = np.int0(box)\n",
      "C:\\Users\\Tanish's\\AppData\\Local\\Temp\\ipykernel_912\\1711883975.py:71: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  aligned_regions = [region for _, region in sorted(zip([cv2.boundingRect(contour)[0] for contour in contours], aligned_regions))]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (10,24) (10,2) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 71\u001b[0m\n\u001b[0;32m     69\u001b[0m     aligned_regions\u001b[39m.\u001b[39mappend(resized_region)\n\u001b[0;32m     70\u001b[0m \u001b[39m# Sort the regions by their x-coordinates\u001b[39;00m\n\u001b[1;32m---> 71\u001b[0m aligned_regions \u001b[39m=\u001b[39m [region \u001b[39mfor\u001b[39;00m _, region \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39;49m(\u001b[39mzip\u001b[39;49m([cv2\u001b[39m.\u001b[39;49mboundingRect(contour)[\u001b[39m0\u001b[39;49m] \u001b[39mfor\u001b[39;49;00m contour \u001b[39min\u001b[39;49;00m contours], aligned_regions))]\n\u001b[0;32m     72\u001b[0m \u001b[39m# Concatenate the sorted regions horizontally\u001b[39;00m\n\u001b[0;32m     73\u001b[0m aligned_regions \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mhstack(aligned_regions)\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (10,24) (10,2) "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\python37\\pytesseract\\tesseract.exe'\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"fak.jpg\")\n",
    "\n",
    "# Convert to grayscale\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Threshold the image\n",
    "thresh = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "# Find contours of text regions\n",
    "\n",
    "contours = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "# print(contours)s\n",
    "\n",
    "# Sort the contours by their x-coordinates\n",
    "contours = sorted(contours, key=lambda c: cv2.boundingRect(c)[0])\n",
    "\n",
    "# Calculate the average height of the contours\n",
    "heights = [cv2.boundingRect(c)[3] for c in contours]\n",
    "avg_height = sum(heights) // len(heights)\n",
    "\n",
    "# Create a list to store the extracted regions\n",
    "regions = []\n",
    "\n",
    "# Adjust the x-coordinates of the contours to align them horizontally\n",
    "x_offset = 0\n",
    "for contour in contours:\n",
    "    # Get the bounding rectangle of the contour\n",
    "    rect = cv2.minAreaRect(contour)\n",
    "    box = cv2.boxPoints(rect)\n",
    "    box = np.int0(box)\n",
    "\n",
    "    # Adjust the x-coordinate of the bounding box\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "    x += x_offset\n",
    "    x_offset += w  # Increment the x offset for the next contour\n",
    "\n",
    "    # Adjust the y-coordinate of the bounding box to center it vertically\n",
    "    y += (avg_height - h) // 2\n",
    "\n",
    "    # Extract the region corresponding to the contour\n",
    "    region = gray_img[y:y+h, x:x+w]\n",
    "\n",
    "    # Add the region to the list of extracted regions\n",
    "    regions.append(region)\n",
    "\n",
    "    # Get the angle of rotation\n",
    "    angle = rect[-1]\n",
    "    z = 1\n",
    "    # Print the bounding box coordinates and angle of rotation\n",
    "    \n",
    "    # print(  f\"Bounding box: Top-left: ({x}, {y}), Bottom-right: ({x + w}, {y + h}), Angle: {angle}\" )\n",
    "\n",
    "# Create a new image with the extracted regions aligned horizontally\n",
    "aligned_regions = []\n",
    "for contour in contours:\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "    # Resize the region to have the same height as the average height\n",
    "    resized_region = cv2.resize(thresh[y:y+h, x:x+w], (w, avg_height))\n",
    "\n",
    "    # Append the resized region to the list of aligned regions\n",
    "    aligned_regions.append(resized_region)\n",
    "# Sort the regions by their x-coordinates\n",
    "aligned_regions = [region for _, region in sorted(zip([cv2.boundingRect(contour)[0] for contour in contours], aligned_regions))]\n",
    "# Concatenate the sorted regions horizontally\n",
    "aligned_regions = np.hstack(aligned_regions)\n",
    "# Show the aligned regions\n",
    "cv2.imwrite(\"alligned.jpg\" , aligned_regions)\n",
    "cv2.imshow(\"Aligned Regions\", aligned_regions)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FOR MULTIPLE IMAGES MODIFIED CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tanish's\\AppData\\Local\\Temp\\ipykernel_12884\\2046223782.py:40: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n",
      "  box = np.int0(box)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "import os\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\python37\\pytesseract\\tesseract.exe'\n",
    "\n",
    "# Define a list of image filenames to process\n",
    "image_filenames = [\"pra1.png\"]\n",
    "\n",
    "for filename in image_filenames:\n",
    "    # Read image\n",
    "    img = cv2.imread(filename)\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Threshold the image\n",
    "    thresh = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "    # Find contours of text regions\n",
    "    contours = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "\n",
    "    # Sort the contours by their x-coordinates\n",
    "    contours = sorted(contours, key=lambda c: cv2.boundingRect(c)[0])\n",
    "\n",
    "    # Calculate the average height of the contours\n",
    "    heights = [cv2.boundingRect(c)[3] for c in contours]\n",
    "    avg_height = sum(heights) // len(heights)\n",
    "\n",
    "    # Create a list to store the extracted regions\n",
    "    regions = []\n",
    "\n",
    "    # Adjust the x-coordinates of the contours to align them horizontally\n",
    "    x_offset = 0\n",
    "    for contour in contours:\n",
    "        # Get the bounding rectangle of the contour\n",
    "        rect = cv2.minAreaRect(contour)\n",
    "        box = cv2.boxPoints(rect)\n",
    "        box = np.int0(box)\n",
    "\n",
    "        # Adjust the x-coordinate of the bounding box\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        x += x_offset\n",
    "        x_offset += w  # Increment the x offset for the next contour\n",
    "\n",
    "        # Extract the region corresponding to the contour\n",
    "        region = gray_img[y:y+h, x:x+w]\n",
    "\n",
    "        # Add the region to the list of extracted regions\n",
    "        regions.append(region)\n",
    "\n",
    "        # Get the angle of rotation\n",
    "        angle = rect[-1]\n",
    "\n",
    "    # Create a new image with the extracted regions aligned horizontally\n",
    "    aligned_regions = []\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "        # Resize the region to have the same height as the average height\n",
    "        resized_region = cv2.resize(thresh[y:y+h, x:x+w], (w, avg_height))\n",
    "\n",
    "        # Append the resized region to the list of aligned regions\n",
    "        aligned_regions.append(resized_region)\n",
    "\n",
    "    # Sort the regions by their x-coordinates\n",
    "    aligned_regions = [region for _, region in sorted(zip([cv2.boundingRect(contour)[0] for contour in contours], aligned_regions))]\n",
    "\n",
    "    # Concatenate the sorted regions horizontally\n",
    "    aligned_regions = np.hstack(aligned_regions)\n",
    "\n",
    "    # Show the aligned regions\n",
    "    cv2.imshow(\"Aligned Regions\", aligned_regions)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "    # Save the aligned regions to a file\n",
    "    aligned_filename = os.path.splitext(filename)[0] + \"_aligned.jpg\"\n",
    "    cv2.imwrite(aligned_filename, aligned_regions)\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adjusting the y-coordinates of the contours to center each line vertically around the average y-coordinate: and trying to sclice the text line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 77\u001b[0m\n\u001b[0;32m     74\u001b[0m     cv2\u001b[39m.\u001b[39mimshow(\u001b[39m\"\u001b[39m\u001b[39mAligned Image\u001b[39m\u001b[39m\"\u001b[39m, aligned_image)\n\u001b[0;32m     75\u001b[0m     cv2\u001b[39m.\u001b[39mwaitKey(\u001b[39m0\u001b[39m)\n\u001b[1;32m---> 77\u001b[0m align_images(image)\n",
      "Cell \u001b[1;32mIn[50], line 59\u001b[0m, in \u001b[0;36malign_images\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m     57\u001b[0m     region \u001b[39m=\u001b[39m line[\u001b[39mint\u001b[39m(y):\u001b[39mint\u001b[39m(y\u001b[39m+\u001b[39mh), \u001b[39mint\u001b[39m(x):\u001b[39mint\u001b[39m(x\u001b[39m+\u001b[39mw)]\n\u001b[0;32m     58\u001b[0m     median_x \u001b[39m=\u001b[39m w \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m---> 59\u001b[0m     new_contour \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([[[x \u001b[39m-\u001b[39m median_x \u001b[39m+\u001b[39m left_offset, y]] \u001b[39mfor\u001b[39;00m (x, y) \u001b[39min\u001b[39;00m contour])\n\u001b[0;32m     60\u001b[0m     region_contours\u001b[39m.\u001b[39mappend(new_contour)\n\u001b[0;32m     63\u001b[0m \u001b[39m# Create a new image with the adjusted contours\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[50], line 59\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     57\u001b[0m     region \u001b[39m=\u001b[39m line[\u001b[39mint\u001b[39m(y):\u001b[39mint\u001b[39m(y\u001b[39m+\u001b[39mh), \u001b[39mint\u001b[39m(x):\u001b[39mint\u001b[39m(x\u001b[39m+\u001b[39mw)]\n\u001b[0;32m     58\u001b[0m     median_x \u001b[39m=\u001b[39m w \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m---> 59\u001b[0m     new_contour \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([[[x \u001b[39m-\u001b[39m median_x \u001b[39m+\u001b[39m left_offset, y]] \u001b[39mfor\u001b[39;00m (x, y) \u001b[39min\u001b[39;00m contour])\n\u001b[0;32m     60\u001b[0m     region_contours\u001b[39m.\u001b[39mappend(new_contour)\n\u001b[0;32m     63\u001b[0m \u001b[39m# Create a new image with the adjusted contours\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread(\"test.jpg\")\n",
    "\n",
    "def align_images(image):\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply adaptive thresholding to segment the image into black and white regions\n",
    "    thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 15, -2)\n",
    "\n",
    "    # Invert the image so that the text is white on a black background\n",
    "    thresh = cv2.bitwise_not(thresh)\n",
    "\n",
    "    # Find contours in the image\n",
    "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Sort the contours from top-to-bottom\n",
    "    contours = sorted(contours, key=lambda ctr: cv2.boundingRect(ctr)[1])\n",
    "\n",
    "    # Extract each line of text\n",
    "    lines = []\n",
    "    for ctr in contours:\n",
    "        x, y, w, h = cv2.boundingRect(ctr)\n",
    "        if w > image.shape[1] / 2:\n",
    "            lines.append(image[y:y+h, x:x+w])\n",
    "\n",
    "    # Get maximum height of all lines\n",
    "    max_height = max([line.shape[0] for line in lines])\n",
    "\n",
    "    # Create a new image with the same width as the original image and the maximum height of all lines\n",
    "    aligned_image = np.zeros((max_height, image.shape[1], 3), np.uint8)\n",
    "\n",
    "    # Paste each line into the aligned image with the same left offset\n",
    "    left_offset = 0\n",
    "    for line in lines:\n",
    "        # Convert the line to grayscale\n",
    "        gray_line = cv2.cvtColor(line, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Apply adaptive thresholding to segment the line into black and white regions\n",
    "        thresh_line = cv2.adaptiveThreshold(gray_line, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 15, -2)\n",
    "\n",
    "        # Invert the line so that the text is white on a black background\n",
    "        thresh_line = cv2.bitwise_not(thresh_line)\n",
    "\n",
    "        # Find contours in the line\n",
    "        line_contours, hierarchy = cv2.findContours(thresh_line, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Sort the contours from left-to-right\n",
    "        line_contours = sorted(line_contours, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
    "\n",
    "        # Extract the region of interest for each contour and adjust the contours\n",
    "        region_contours = []\n",
    "        for contour in line_contours:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            region = line[int(y):int(y+h), int(x):int(x+w)]\n",
    "            median_x = w // 2\n",
    "            new_contour = np.array([[[x - median_x + left_offset, y]] for (x, y) in contour])\n",
    "            region_contours.append(new_contour)\n",
    "\n",
    "\n",
    "        # Create a new image with the adjusted contours\n",
    "        aligned_region = np.zeros_like(thresh_line)\n",
    "        cv2.drawContours(aligned_region, region_contours, -1, (255, 255, 255), -1)\n",
    "\n",
    "        # Paste the aligned region into the aligned image\n",
    "        aligned_image[0:line.shape[0], left_offset:left_offset+line.shape[1]] = aligned_region\n",
    "\n",
    "        # Update the left offset\n",
    "        left_offset += line.shape[1]\n",
    "\n",
    "    # Show the aligned image\n",
    "    cv2.imshow(\"Aligned Image\", aligned_image)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "align_images(image)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trying to work on bounding boxes insted of contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load image\n",
    "image = cv2.imread('fak.jpg')\n",
    "\n",
    "# Convert to grayscale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Threshold image\n",
    "_, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "# Find contours\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Sort contours from left to right based on their x-coordinates\n",
    "contours = sorted(contours, key=lambda c: cv2.boundingRect(c)[0])\n",
    "\n",
    "# Get the bounding boxes of each contour\n",
    "boxes = [cv2.boundingRect(c) for c in contours]\n",
    "\n",
    "# Align the bounding boxes based on the previous box\n",
    "aligned_boxes = [boxes[0]]\n",
    "for i in range(1, len(boxes)):\n",
    "    # Get the current and previous boxes\n",
    "    current_box = boxes[i]\n",
    "    previous_box = aligned_boxes[-1]\n",
    "    \n",
    "    # Calculate the distance between the bottom of the previous box and the top of the current box\n",
    "    y_distance = current_box[1] - (previous_box[1] + previous_box[3])\n",
    "    \n",
    "    # Shift the current box vertically to align it with the previous box\n",
    "    aligned_box = (current_box[0], previous_box[1] + previous_box[3] + y_distance, current_box[2], current_box[3])\n",
    "    \n",
    "    # Add the aligned box to the list of aligned boxes\n",
    "    aligned_boxes.append(aligned_box)\n",
    "\n",
    "# Draw the aligned boxes on a new image\n",
    "aligned_image = np.zeros_like(image)\n",
    "for box in aligned_boxes:\n",
    "    x, y, w, h = box\n",
    "    cv2.rectangle(aligned_image, (x, y), (x + w, y + h), (255, 255, 255), -1)\n",
    "\n",
    "# Bitwise AND the original image with the aligned boxes to get the aligned text\n",
    "aligned_text = cv2.bitwise_and(image, aligned_image)\n",
    "\n",
    "# Display the original image and the aligned text\n",
    "cv2.imshow('Original Image', image)\n",
    "cv2.imshow('Aligned Text', aligned_text)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bounging box align according to minimum x to maximum x works good on non skwed image but showing error on skwed images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (20,18,3) into shape (33,18,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 32\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[39mfor\u001b[39;00m i, bbox \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(bounding_boxes):\n\u001b[0;32m     31\u001b[0m     x, y, w, h \u001b[39m=\u001b[39m bbox\n\u001b[1;32m---> 32\u001b[0m     aligned_img[y:y\u001b[39m+\u001b[39;49mmax_height, x:x\u001b[39m+\u001b[39;49mw] \u001b[39m=\u001b[39m img[y:y\u001b[39m+\u001b[39mh, x:x\u001b[39m+\u001b[39mw]\n\u001b[0;32m     34\u001b[0m \u001b[39m# Display the aligned image\u001b[39;00m\n\u001b[0;32m     35\u001b[0m cv2\u001b[39m.\u001b[39mimshow(\u001b[39m'\u001b[39m\u001b[39mAligned Image\u001b[39m\u001b[39m'\u001b[39m, aligned_img)\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (20,18,3) into shape (33,18,3)"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "img = cv2.imread('fak.jpg')\n",
    "\n",
    "# Convert to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Threshold the image to convert to binary\n",
    "_, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "# Find contours in the binary image\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Find the bounding boxes for each contour\n",
    "bounding_boxes = [cv2.boundingRect(c) for c in contours]\n",
    "\n",
    "# Sort the bounding boxes by x coordinate\n",
    "bounding_boxes = sorted(bounding_boxes, key=lambda x: x[0])\n",
    "\n",
    "# Compute the maximum bounding box width and height\n",
    "max_width = max([b[2] for b in bounding_boxes])\n",
    "max_height = max([b[3] for b in bounding_boxes])\n",
    "\n",
    "# Create a new image with the same dimensions as the original image\n",
    "aligned_img = np.zeros_like(img)\n",
    "\n",
    "# Loop over each bounding box and paste the corresponding region of the original image\n",
    "for i, bbox in enumerate(bounding_boxes):\n",
    "    x, y, w, h = bbox\n",
    "    aligned_img[y:y+max_height, x:x+w] = img[y:y+h, x:x+w]\n",
    "\n",
    "# Display the aligned image\n",
    "cv2.imshow('Aligned Image', aligned_img)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tanish's\\AppData\\Local\\Temp\\ipykernel_7776\\355317477.py:13: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n",
      "  box = np.int0(box)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def align_text(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "    contours = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "    contours = sorted(contours, key=cv2.boundingRect)\n",
    "\n",
    "    rect = cv2.minAreaRect(contours[0])\n",
    "    box = cv2.boxPoints(rect)\n",
    "    box = np.int0(box)\n",
    "\n",
    "    width = int(rect[1][0])\n",
    "    height = int(rect[1][1])\n",
    "\n",
    "    src_pts = box.astype(\"float32\")\n",
    "    dst_pts = np.array([[0, height - 1],\n",
    "                        [0, 0],\n",
    "                        [width - 1, 0],\n",
    "                        [width - 1, height - 1]], dtype=\"float32\")\n",
    "\n",
    "    M = cv2.getPerspectiveTransform(src_pts, dst_pts)\n",
    "    aligned_image = cv2.warpPerspective(image, M, (width, height))\n",
    "\n",
    "    cv2.imshow(\"ali\",aligned_image)\n",
    "\n",
    "image = cv2.imread('www.png')\n",
    "align_text(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tanish's\\AppData\\Local\\Temp\\ipykernel_912\\523097439.py:38: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n",
      "  box = np.int0(box)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\python37\\pytesseract\\tesseract.exe'\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"repo1.jpg\")\n",
    "\n",
    "# Convert to grayscale\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Threshold the image\n",
    "thresh = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "# Find contours of text regions\n",
    "\n",
    "contours = cv2.findContours(thresh, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "# print(contours)s\n",
    "\n",
    "# Sort the contours by their x-coordinates\n",
    "contours = sorted(contours, key=lambda c: cv2.boundingRect(c)[0])\n",
    "\n",
    "\n",
    "# Calculate the average height of the contours\n",
    "heights = [cv2.boundingRect(c)[3] for c in contours]\n",
    "avg_height = sum(heights) // len(heights)\n",
    "\n",
    "# Create a list to store the extracted regions\n",
    "regions = []\n",
    "\n",
    "# Adjust the x-coordinates of the contours to align them horizontally\n",
    "x_offset = 0\n",
    "for contour in contours:\n",
    "    # Get the bounding rectangle of the contour\n",
    "    rect = cv2.minAreaRect(contour)\n",
    "    box = cv2.boxPoints(rect)\n",
    "    box = np.int0(box)\n",
    "\n",
    "    # Adjust the x-coordinate of the bounding box\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "    x += x_offset\n",
    "    x_offset += w  # Increment the x offset for the next contour\n",
    "\n",
    "    # Adjust the y-coordinate of the bounding box to center it vertically\n",
    "    # y += (avg_height - h) // 2\n",
    "\n",
    "    # Extract the region corresponding to the contour\n",
    "    region = gray_img[y:y+h, x:x+w]\n",
    "\n",
    "    # Add the region to the list of extracted regions\n",
    "    regions.append(region)\n",
    "\n",
    "    # Get the angle of rotation\n",
    "    angle = rect[-1]\n",
    "    z = 1\n",
    "    # Print the bounding box coordinates and angle of rotation\n",
    "    \n",
    "#    print(  f\"Bounding box: Top-left: ({x}, {y}), Bottom-right: ({x + w}, {y + h}), Angle: {angle}\" )\n",
    "\n",
    "# Create a new image with the extracted regions aligned horizontally\n",
    "aligned_regions = []\n",
    "for contour in contours:\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "    # Resize the region to have the same height as the average height\n",
    "    resized_region = cv2.resize(thresh[y:y+h, x:x+w], (w, avg_height))\n",
    "\n",
    "    # Append the resized region to the list of aligned regions\n",
    "    aligned_regions.append(resized_region)\n",
    "# Sort the regions by their x-coordinates\n",
    "aligned_regions = [region for _, region in sorted(zip([cv2.boundingRect(contour)[0] for contour in contours], aligned_regions))]\n",
    "# Concatenate the sorted regions horizontally\n",
    "aligned_regions = np.hstack(aligned_regions)\n",
    "# Show the aligned regions\n",
    "cv2.imwrite(\"alligned.jpg\" , aligned_regions)\n",
    "cv2.imshow(\"Aligned Regions\", aligned_regions)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
